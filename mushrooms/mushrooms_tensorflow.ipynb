{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]]\n",
      "(0, array([[1, 1],\n",
      "       [0, 0],\n",
      "       [2, 2]]), array([['b'],\n",
      "       ['a'],\n",
      "       ['c']], dtype='<U1'))\n",
      "(1, array([[3, 3]]), array([['d']], dtype='<U1'))\n",
      "(0, array([[2, 2],\n",
      "       [0, 0],\n",
      "       [3, 3]]), array([['c'],\n",
      "       ['a'],\n",
      "       ['d']], dtype='<U1'))\n",
      "(1, array([[1, 1]]), array([['b']], dtype='<U1'))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SCRIPT_DIR = Path.cwd()\n",
    "sys.path.append(str(SCRIPT_DIR.parent))\n",
    "\n",
    "from data_utils.data_iterator import DataIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(open(\"training_data/mushrooms_training_data.npy\", 'rb'))\n",
    "training_labels = np.load(open(\"training_data/mushrooms_training_labels.npy\", 'rb'))\n",
    "validation_data = np.load(open(\"training_data/mushrooms_validation_data.npy\", 'rb'))\n",
    "validation_labels = np.load(open(\"training_data/mushrooms_validation_labels.npy\", 'rb'))\n",
    "test_data = np.load(open(\"training_data/mushrooms_test_data.npy\", 'rb'))\n",
    "test_labels = np.load(open(\"training_data/mushrooms_test_labels.npy\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 117)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model hyperparameters and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "hidden_1_units = 50\n",
    "hidden_1_activation = tf.nn.relu\n",
    "hidden_2_units = 20\n",
    "hidden_2_activation = tf.nn.relu\n",
    "hidden_3_units = 5\n",
    "hidden_3_activation = tf.nn.relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, training_data.shape[1]], name=\"inputs\")\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 1], name=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hidden layers and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_1 = tf.layers.dense(x, units=hidden_1_units, activation=hidden_1_activation, name=\"hidden_1\")\n",
    "fully_connected_2 = tf.layers.dense(fully_connected_1, units=hidden_2_units, activation=hidden_2_activation, name=\"hidden_2\")\n",
    "fully_connected_3 = tf.layers.dense(fully_connected_2, units=hidden_3_units, activation=hidden_3_activation, name=\"hidden_3\")\n",
    "output_layer = tf.layers.dense(fully_connected_3, units=1, activation=tf.nn.sigmoid, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.variable_scope(\"Cost_and_Optimizer\"):\n",
    "    loss_op = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output_layer, name=\"loss_op\")\n",
    "    cost = tf.reduce_sum(loss_op, name=\"cost\")\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lists of batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iterator = DataIterator(training_data, training_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch N°: 0 - Batch N°: 0\n",
      "Training cost = 365.53662109375 - Training accuracy = 42.578125%\n",
      "Validation cost = 578.06396484375 - Validation accuracy = 40.02463054187192%\n",
      "Epoch N°: 0 - Batch N°: 5\n",
      "Training cost = 366.5616455078125 - Training accuracy = 50.9765625%\n",
      "Validation cost = 568.5856323242188 - Validation accuracy = 47.53694581280788%\n",
      "Epoch N°: 0 - Batch N°: 10\n",
      "Training cost = 344.6744384765625 - Training accuracy = 50.0%\n",
      "Validation cost = 539.0370483398438 - Validation accuracy = 47.53694581280788%\n",
      "Epoch N°: 1 - Batch N°: 0\n",
      "Training cost = 333.656005859375 - Training accuracy = 49.8046875%\n",
      "Validation cost = 523.320068359375 - Validation accuracy = 47.53694581280788%\n",
      "Epoch N°: 1 - Batch N°: 5\n",
      "Training cost = 313.81927490234375 - Training accuracy = 46.2890625%\n",
      "Validation cost = 502.629150390625 - Validation accuracy = 47.53694581280788%\n",
      "Epoch N°: 1 - Batch N°: 10\n",
      "Training cost = 309.36956787109375 - Training accuracy = 67.3828125%\n",
      "Validation cost = 491.5146484375 - Validation accuracy = 67.48768472906403%\n",
      "Epoch N°: 2 - Batch N°: 0\n",
      "Training cost = 307.94586181640625 - Training accuracy = 84.765625%\n",
      "Validation cost = 486.8446350097656 - Validation accuracy = 82.01970443349754%\n",
      "Epoch N°: 2 - Batch N°: 5\n",
      "Training cost = 298.30865478515625 - Training accuracy = 90.8203125%\n",
      "Validation cost = 479.1499328613281 - Validation accuracy = 88.91625615763546%\n",
      "Epoch N°: 2 - Batch N°: 10\n",
      "Training cost = 300.918701171875 - Training accuracy = 94.53125%\n",
      "Validation cost = 472.6891174316406 - Validation accuracy = 90.51724137931035%\n",
      "Epoch N°: 3 - Batch N°: 0\n",
      "Training cost = 295.1824951171875 - Training accuracy = 95.5078125%\n",
      "Validation cost = 468.4024353027344 - Validation accuracy = 93.59605911330048%\n",
      "Epoch N°: 3 - Batch N°: 5\n",
      "Training cost = 292.400390625 - Training accuracy = 96.875%\n",
      "Validation cost = 459.8877258300781 - Validation accuracy = 95.32019704433498%\n",
      "Epoch N°: 3 - Batch N°: 10\n",
      "Training cost = 287.3421630859375 - Training accuracy = 96.2890625%\n",
      "Validation cost = 448.6785888671875 - Validation accuracy = 95.93596059113301%\n",
      "Epoch N°: 4 - Batch N°: 0\n",
      "Training cost = 277.49169921875 - Training accuracy = 97.8515625%\n",
      "Validation cost = 442.48175048828125 - Validation accuracy = 95.93596059113301%\n",
      "Epoch N°: 4 - Batch N°: 5\n",
      "Training cost = 276.6960144042969 - Training accuracy = 97.265625%\n",
      "Validation cost = 431.85107421875 - Validation accuracy = 96.67487684729063%\n",
      "Epoch N°: 4 - Batch N°: 10\n",
      "Training cost = 269.31500244140625 - Training accuracy = 96.6796875%\n",
      "Validation cost = 425.5966491699219 - Validation accuracy = 96.79802955665025%\n",
      "Epoch N°: 5 - Batch N°: 0\n",
      "Training cost = 271.2199401855469 - Training accuracy = 97.4609375%\n",
      "Validation cost = 423.74359130859375 - Validation accuracy = 96.67487684729063%\n",
      "Epoch N°: 5 - Batch N°: 5\n",
      "Training cost = 272.5159912109375 - Training accuracy = 96.875%\n",
      "Validation cost = 420.4258117675781 - Validation accuracy = 97.04433497536947%\n",
      "Epoch N°: 5 - Batch N°: 10\n",
      "Training cost = 254.8638916015625 - Training accuracy = 98.046875%\n",
      "Validation cost = 418.595947265625 - Validation accuracy = 97.16748768472905%\n",
      "Epoch N°: 6 - Batch N°: 0\n",
      "Training cost = 267.15081787109375 - Training accuracy = 97.65625%\n",
      "Validation cost = 417.8156433105469 - Validation accuracy = 97.41379310344827%\n",
      "Epoch N°: 6 - Batch N°: 5\n",
      "Training cost = 269.0521240234375 - Training accuracy = 98.046875%\n",
      "Validation cost = 416.599365234375 - Validation accuracy = 97.53694581280789%\n",
      "Epoch N°: 6 - Batch N°: 10\n",
      "Training cost = 263.875244140625 - Training accuracy = 98.2421875%\n",
      "Validation cost = 415.95660400390625 - Validation accuracy = 97.53694581280789%\n",
      "Epoch N°: 7 - Batch N°: 0\n",
      "Training cost = 266.824951171875 - Training accuracy = 97.4609375%\n",
      "Validation cost = 415.5262451171875 - Validation accuracy = 97.53694581280789%\n",
      "Epoch N°: 7 - Batch N°: 5\n",
      "Training cost = 258.65625 - Training accuracy = 97.8515625%\n",
      "Validation cost = 414.94757080078125 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 7 - Batch N°: 10\n",
      "Training cost = 267.6460266113281 - Training accuracy = 98.6328125%\n",
      "Validation cost = 414.5346984863281 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 8 - Batch N°: 0\n",
      "Training cost = 266.08795166015625 - Training accuracy = 98.6328125%\n",
      "Validation cost = 414.4950256347656 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 8 - Batch N°: 5\n",
      "Training cost = 261.2550048828125 - Training accuracy = 98.6328125%\n",
      "Validation cost = 414.24224853515625 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 8 - Batch N°: 10\n",
      "Training cost = 259.32806396484375 - Training accuracy = 99.0234375%\n",
      "Validation cost = 413.7398986816406 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 9 - Batch N°: 0\n",
      "Training cost = 261.0570068359375 - Training accuracy = 99.0234375%\n",
      "Validation cost = 413.683349609375 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 9 - Batch N°: 5\n",
      "Training cost = 265.35418701171875 - Training accuracy = 98.046875%\n",
      "Validation cost = 413.5216979980469 - Validation accuracy = 97.66009852216749%\n",
      "Epoch N°: 9 - Batch N°: 10\n",
      "Training cost = 265.3934326171875 - Training accuracy = 97.8515625%\n",
      "Validation cost = 413.1031799316406 - Validation accuracy = 97.66009852216749%\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar(\"Cost\", cost)\n",
    "tf.summary.histogram(\"fully_connected_1\", fully_connected_1)\n",
    "tf.summary.histogram(\"output_layer\", output_layer)\n",
    "\n",
    "with tf.variable_scope('hidden_1', reuse=True):\n",
    "    weights = tf.get_variable('kernel')\n",
    "    \n",
    "tf.summary.histogram(\"weights_fully_1\", weights)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "    # Handle old tensorboard file with same hyperparameters\n",
    "    tensorboard_job_name = \"{}-{}-{}-lr_{}-e_{}-b_{}\".format(hidden_1_units, hidden_2_units, hidden_3_units,\n",
    "                                                             learning_rate, epochs, batch_size)\n",
    "    tensorboard_log_dir = Path(Path.cwd(), \"tensoboard_logs\", tensorboard_job_name)\n",
    "    writer = tf.summary.FileWriter(\"./tensoboard_logs/{}\".format(tensorboard_job_name))\n",
    "    if len(list(tensorboard_log_dir.iterdir())) > 0:\n",
    "        for file in list(tensorboard_log_dir.iterdir()):\n",
    "            file.unlink()\n",
    "    \n",
    "    writer.add_graph(tf.get_default_graph())\n",
    "    \n",
    "    training_steps = 0\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for i, training_data_batch, training_labels_batch in training_iterator:\n",
    "            \n",
    "            if i%5 == 0:\n",
    "                \n",
    "                output, batch_cost = sess.run([output_layer, cost], feed_dict={x: training_data_batch,\n",
    "                                                                               y: training_labels_batch})\n",
    "                \n",
    "                predictions = output > 0.5\n",
    "                accuracy = np.sum(training_labels_batch == predictions) / training_labels_batch.shape[0]\n",
    "                \n",
    "                validation_output, validation_cost = sess.run([output_layer, cost], feed_dict={x: validation_data,\n",
    "                                                                                               y: validation_labels})\n",
    "                validation_predictions = validation_output > 0.5\n",
    "                validation_accuracy = np.sum(validation_labels == validation_predictions) / validation_labels.shape[0]\n",
    "                \n",
    "                print(\"Epoch N°: {} - Batch N°: {}\\n\"\n",
    "                      \"Training cost = {} - Training accuracy = {}%\\n\"\n",
    "                      \"Validation cost = {} - Validation accuracy = {}%\".format(e, i, batch_cost, accuracy * 100,\n",
    "                                                                               validation_cost, validation_accuracy * 100))\n",
    "            \n",
    "            s = sess.run(merged_summary, feed_dict={x: training_data_batch, y: training_labels_batch})\n",
    "            writer.add_summary(s, training_steps)\n",
    "            training_steps += 1\n",
    "            \n",
    "            sess.run(train, feed_dict={x: training_data_batch, y: training_labels_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "To use tensorboard open a console, go to the project folder (`\"mushrooms\"`) type:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir tensoboard_logs\\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensoboard results\n",
    "\n",
    "![output_layer_histograms](output_layer_histograms.png)\n",
    "![graph](graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
