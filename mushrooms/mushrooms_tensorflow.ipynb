{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(open(\"training_data/mushrooms_training_data.npy\", 'rb'))\n",
    "training_labels = np.load(open(\"training_data/mushrooms_training_labels.npy\", 'rb'))\n",
    "validation_data = np.load(open(\"training_data/mushrooms_validation_data.npy\", 'rb'))\n",
    "validation_labels = np.load(open(\"training_data/mushrooms_validation_labels.npy\", 'rb'))\n",
    "test_data = np.load(open(\"training_data/mushrooms_test_data.npy\", 'rb'))\n",
    "test_labels = np.load(open(\"training_data/mushrooms_test_labels.npy\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 117)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model hyperparameters and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "hidden_1_units = 50\n",
    "hidden_1_activation = tf.nn.relu\n",
    "hidden_2_units = 20\n",
    "hidden_2_activation = tf.nn.relu\n",
    "hidden_3_units = 5\n",
    "hidden_3_activation = tf.nn.relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, training_data.shape[1]], name=\"inputs\")\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 1], name=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hidden layers and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_1 = tf.layers.dense(x, units=hidden_1_units, activation=hidden_1_activation, name=\"hidden_1\")\n",
    "fully_connected_2 = tf.layers.dense(fully_connected_1, units=hidden_2_units, activation=hidden_2_activation, name=\"hidden_2\")\n",
    "fully_connected_3 = tf.layers.dense(fully_connected_2, units=hidden_3_units, activation=hidden_3_activation, name=\"hidden_3\")\n",
    "output_layer = tf.layers.dense(fully_connected_3, units=1, activation=tf.nn.sigmoid, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.variable_scope(\"Cost_and_Optimizer\"):\n",
    "    cost = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output_layer, name=\"cost\"))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lists of batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_full_batchs = round(training_data.shape[0] / batch_size)\n",
    "\n",
    "training_data_batchs = []\n",
    "training_labels_batchs = []\n",
    "\n",
    "for j in range(training_full_batchs):\n",
    "    training_data_batchs.append(training_data[j * batch_size:(j+1) * batch_size, :])\n",
    "    training_labels_batchs.append(training_labels[j * batch_size:(j+1) * batch_size, :])\n",
    "\n",
    "validation_full_batchs = round(validation_data.shape[0] / batch_size)\n",
    "\n",
    "validation_data_batchs = []\n",
    "validation_labels_batchs = []\n",
    "\n",
    "for j in range(validation_full_batchs):\n",
    "    validation_data_batchs.append(validation_data[j * batch_size:(j+1) * batch_size, :])\n",
    "    validation_labels_batchs.append(validation_labels[j * batch_size:(j+1) * batch_size, :])\n",
    "    \n",
    "validation_data_batchs.append(np.array(validation_data[validation_full_batchs * batch_size:, :]))\n",
    "validation_labels_batchs.append(np.array(validation_labels[validation_full_batchs * batch_size:, :]))\n",
    "\n",
    "test_full_batchs = round(test_data.shape[0] / batch_size)\n",
    "\n",
    "test_data_batchs = []\n",
    "test_labels_batchs = []\n",
    "\n",
    "for j in range(test_full_batchs):\n",
    "    test_data_batchs.append(test_data[j * batch_size:(j+1) * batch_size, :])\n",
    "    test_labels_batchs.append(test_labels[j * batch_size:(j+1) * batch_size, :])\n",
    "\n",
    "test_data_batchs.append(np.array(test_data[test_full_batchs * batch_size:, :]))\n",
    "test_labels_batchs.append(np.array(test_labels[test_full_batchs * batch_size:, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch N°: 0 - Batch N°: 0 - Cost = 364.5845947265625 - Accuracy = 47.0703125%\n",
      "Epoch N°: 0 - Batch N°: 5 - Cost = 366.08380126953125 - Accuracy = 64.6484375%\n",
      "Epoch N°: 0 - Batch N°: 10 - Cost = 345.57080078125 - Accuracy = 47.265625%\n",
      "Epoch N°: 1 - Batch N°: 0 - Cost = 348.2217102050781 - Accuracy = 54.4921875%\n",
      "Epoch N°: 1 - Batch N°: 5 - Cost = 335.60784912109375 - Accuracy = 64.84375%\n",
      "Epoch N°: 1 - Batch N°: 10 - Cost = 309.299072265625 - Accuracy = 81.4453125%\n",
      "Epoch N°: 2 - Batch N°: 0 - Cost = 305.38421630859375 - Accuracy = 88.8671875%\n",
      "Epoch N°: 2 - Batch N°: 5 - Cost = 293.15692138671875 - Accuracy = 93.9453125%\n",
      "Epoch N°: 2 - Batch N°: 10 - Cost = 272.88427734375 - Accuracy = 93.1640625%\n",
      "Epoch N°: 3 - Batch N°: 0 - Cost = 272.7220153808594 - Accuracy = 96.6796875%\n",
      "Epoch N°: 3 - Batch N°: 5 - Cost = 272.08343505859375 - Accuracy = 96.09375%\n",
      "Epoch N°: 3 - Batch N°: 10 - Cost = 260.091064453125 - Accuracy = 95.3125%\n",
      "Epoch N°: 4 - Batch N°: 0 - Cost = 263.08416748046875 - Accuracy = 97.65625%\n",
      "Epoch N°: 4 - Batch N°: 5 - Cost = 266.51190185546875 - Accuracy = 96.6796875%\n",
      "Epoch N°: 4 - Batch N°: 10 - Cost = 255.91639709472656 - Accuracy = 96.09375%\n",
      "Epoch N°: 5 - Batch N°: 0 - Cost = 259.875732421875 - Accuracy = 98.4375%\n",
      "Epoch N°: 5 - Batch N°: 5 - Cost = 264.00823974609375 - Accuracy = 97.65625%\n",
      "Epoch N°: 5 - Batch N°: 10 - Cost = 253.6981201171875 - Accuracy = 97.265625%\n",
      "Epoch N°: 6 - Batch N°: 0 - Cost = 258.2791748046875 - Accuracy = 99.0234375%\n",
      "Epoch N°: 6 - Batch N°: 5 - Cost = 262.43218994140625 - Accuracy = 98.828125%\n",
      "Epoch N°: 6 - Batch N°: 10 - Cost = 252.338623046875 - Accuracy = 98.046875%\n",
      "Epoch N°: 7 - Batch N°: 0 - Cost = 257.3033142089844 - Accuracy = 99.0234375%\n",
      "Epoch N°: 7 - Batch N°: 5 - Cost = 261.343994140625 - Accuracy = 99.0234375%\n",
      "Epoch N°: 7 - Batch N°: 10 - Cost = 251.44192504882812 - Accuracy = 98.2421875%\n",
      "Epoch N°: 8 - Batch N°: 0 - Cost = 256.5440673828125 - Accuracy = 99.0234375%\n",
      "Epoch N°: 8 - Batch N°: 5 - Cost = 260.52398681640625 - Accuracy = 99.0234375%\n",
      "Epoch N°: 8 - Batch N°: 10 - Cost = 250.77197265625 - Accuracy = 98.4375%\n",
      "Epoch N°: 9 - Batch N°: 0 - Cost = 255.804443359375 - Accuracy = 99.21875%\n",
      "Epoch N°: 9 - Batch N°: 5 - Cost = 259.81182861328125 - Accuracy = 99.4140625%\n",
      "Epoch N°: 9 - Batch N°: 10 - Cost = 250.03973388671875 - Accuracy = 98.4375%\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar(\"Cost\", cost)\n",
    "tf.summary.histogram(\"fully_connected_1\", fully_connected_1)\n",
    "tf.summary.histogram(\"output_layer\", output_layer)\n",
    "\n",
    "with tf.variable_scope('hidden_1', reuse=True):\n",
    "    weights = tf.get_variable('kernel')\n",
    "    \n",
    "tf.summary.histogram(\"weights_fully_1\", weights)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "    # Handle old tensorboard file with same hyperparameters\n",
    "    tensorboard_job_name = \"{}-{}-{}-lr_{}-e_{}-b_{}\".format(hidden_1_units, hidden_2_units, hidden_3_units,\n",
    "                                                             learning_rate, epochs, batch_size)\n",
    "    tensorboard_log_dir = Path(Path.cwd(), \"tensoboard_logs\", tensorboard_job_name)\n",
    "    writer = tf.summary.FileWriter(\"./tensoboard_logs/{}\".format(tensorboard_job_name))\n",
    "    if len(list(tensorboard_log_dir.iterdir())) > 0:\n",
    "        for file in list(tensorboard_log_dir.iterdir()):\n",
    "            file.unlink()\n",
    "    \n",
    "    writer.add_graph(tf.get_default_graph())\n",
    "    \n",
    "    training_steps = 0\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for i in range(len(training_data_batchs)):\n",
    "            \n",
    "            if i%5 == 0:\n",
    "                \n",
    "                output, batch_cost = sess.run([output_layer, cost], feed_dict={x: training_data_batchs[i],\n",
    "                                                                         y: training_labels_batchs[i]})\n",
    "                \n",
    "                predictions = output > 0.5\n",
    "                accuracy = np.sum(training_labels_batchs[i] == predictions) / training_labels_batchs[i].shape[0]\n",
    "                \n",
    "                print(\"Epoch N°: {} - Batch N°: {} - Cost = {} - Accuracy = {}%\".format(e, i, batch_cost, accuracy * 100))\n",
    "            \n",
    "                \n",
    "            s = sess.run(merged_summary, feed_dict={x: training_data_batchs[i], y: training_labels_batchs[i]})\n",
    "            writer.add_summary(s, training_steps)\n",
    "            training_steps += 1\n",
    "            \n",
    "            sess.run(train, feed_dict={x: training_data_batchs[i], y: training_labels_batchs[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "To use tensorboard open a console, go to the project folder (`\"mushrooms\"`) type:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir tensoboard_logs\\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensoboard results\n",
    "\n",
    "![output_layer_histograms](output_layer_histograms.png)\n",
    "![graph](graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
